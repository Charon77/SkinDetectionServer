{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import operator\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "IS_TRAINING = False\n",
    "IS_IGNORE_INPUT = False\n",
    "\n",
    "#sys.argv[1] = \"skindetectserver/uploads/baked.vegetables.1.jpg\"\n",
    "\n",
    "if not IS_TRAINING and not IS_IGNORE_INPUT:\n",
    "    # Check file exists        \n",
    "    validate_filename = sys.argv[1]\n",
    "    print(\"Filename: \", validate_filename)\n",
    "    if not (os.path.isfile(validate_filename)):\n",
    "        print(\"File not found\")\n",
    "        exit()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "NUM_OF_CLASS = 2\n",
    "IMG_X = 128\n",
    "IMG_Y = 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CoordinatorScope:\n",
    "    def __enter__(self):\n",
    "        self.threads = []\n",
    "        self.coord = tf.train.Coordinator()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.coord.request_stop()\n",
    "        self.coord.join(self.threads)\n",
    "    def regThread(self, threads: '[Thread]'):\n",
    "        self.threads += threads\n",
    "\n",
    "\n",
    "class ThreadScope:\n",
    "    def __init__(self, coordScope: CoordinatorScope):\n",
    "        self.coordScope = coordScope\n",
    "        self.coord = coordScope.coord\n",
    "    def __enter__(self):\n",
    "        self.coordScope.regThread(tf.train.start_queue_runners(coord=self.coord))\n",
    "    def __exit__(self, *args):\n",
    "        pass #coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#filename_queue = tf.train.string_input_producer([\n",
    "#    'train/gut_high (1).jpg',\n",
    "#    'train/gut_high (2).jpg',\n",
    "#    'train/nail_mid (1).jpg']) #  list of files to read\n",
    "\n",
    "filename_healthy_queue = tf.train.string_input_producer(tf.train.match_filenames_once('food_training/Healthy/*.jpg'))\n",
    "filename_junk_queue = tf.train.string_input_producer(tf.train.match_filenames_once('food_training/Junk/*.jpg'))\n",
    "\n",
    "reader = tf.WholeFileReader()\n",
    "keyH, valueH = reader.read(filename_healthy_queue)\n",
    "keyJ, valueJ = reader.read(filename_junk_queue)\n",
    "\n",
    "#print(value)\n",
    "#print(key)\n",
    "\n",
    "def get_img():\n",
    "    return tf.cond(\n",
    "    tf.less(\n",
    "    tf.random_uniform([1])[0], 0.5), \n",
    "    (lambda: (valueH, tf.constant([1,0])  )) , \n",
    "    (lambda: (valueJ, tf.constant([0,1])  )) )\n",
    "\n",
    "\n",
    "#my_img = tf.placeholder(tf.zeros([IMG_X, IMG_Y , 3]), name=\"imgVar\")\n",
    "# healthy_img = tf.reshape(tf.to_float(tf.image.decode_jpeg(valueH)), [IMG_X, IMG_Y, 3]) # use png or jpg decoder based on your files.\n",
    "# junk_img = tf.reshape(tf.to_float(tf.image.decode_jpeg(valueJ)), [IMG_X, IMG_Y, 3]) # use png or jpg decoder based on your files.\n",
    "imgA, label = get_img()\n",
    "img = tf.reshape(tf.to_float(tf.image.decode_jpeg(imgA)), [IMG_X, IMG_Y, 3]) # use png or jpg decoder based on your files.\n",
    "#adding key\n",
    "\n",
    "#my_img = tf.pack([my_img, key])\n",
    "\n",
    "\n",
    "#_label = [[1,0], [1,0], [0,1] ]\n",
    "#label = tf.reshape(_label, [-1,  2])\n",
    "\n",
    "##TEST\n",
    "\n",
    "#with sess.as_default() as sess:\n",
    "#    sess.run(tf.global_variables_initializer())\n",
    "#    coord = tf.train.Coordinator()\n",
    "#    threads = tf.train.start_queue_runners(coord=coord)\n",
    "#    \n",
    "# filename_before_slash = tf.sparse_tensor_to_dense(tf.string_split([key], delimiter='/'), default_value=\"x\")[0][1]\n",
    "# filename_before_space = tf.sparse_tensor_to_dense(tf.string_split([filename_before_slash], delimiter=' '), default_value=\"x\")[0][0]\n",
    "\n",
    "\n",
    "# hashed_index = tf.string_to_hash_bucket_strong(filename_before_space, NUM_OF_CLASS, [4758937974, 729479902])\n",
    "\n",
    "# label = tf.one_hot(hashed_index, NUM_OF_CLASS)\n",
    "    \n",
    "# tf.summary.histogram(\"Label_hashed_index\",hashed_index)\n",
    "    \n",
    "healthy_label = [1, 0]\n",
    "junk_label = [0, 1]\n",
    "\n",
    "batch_size = 60\n",
    "min_after_dequeue = 1000\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "example_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [img, label],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "\n",
    "#    print(sess.run( [label ,filename_before_space] ))\n",
    "#    print(sess.run( [label ,filename_before_space] ))\n",
    "#    print(sess.run( [label ,filename_before_space] ))\n",
    "#    print(sess.run( [label ,filename_before_space] ))\n",
    "#    print(sess.run( [label ,filename_before_space] ))\n",
    "#    \n",
    "#    #print(sess.run(my_img))\n",
    "#    \n",
    "#    coord.request_stop()\n",
    "#    coord.join(threads)\n",
    "\n",
    "#example_batch, label_batch = tf.train.shuffle_batch(\n",
    "# init_op = tf.initialize_all_variables()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op)\n",
    "# \n",
    "#     # Start populating the filename queue.\n",
    "#     print(\"A\")\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "#     print(\"B\")\n",
    "#     for i in range(1): #length of your filename list\n",
    "#         image = my_img.eval() #here is your image Tensor :) \n",
    "#     print(\"C\")\n",
    "#     print(image.shape)\n",
    "#     #Image.show(Image.fromarray(np.asarray(image)))\n",
    "# \n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, IMG_X * IMG_Y * 3], name=\"placeholderX\")\n",
    "\n",
    "#x = tf.Variable(tf.zeros([1, IMG_X * IMG_Y * 3]), name=\"placeholderX\")\n",
    "\n",
    "#x = tf.pack([tf.reshape(tf.to_float(my_img), [IMG_X * IMG_Y * 3]), tf.reshape(tf.to_float(my_img), [IMG_X * IMG_Y * 3]), tf.reshape(tf.to_float(my_img), [IMG_X * IMG_Y * 3])])\n",
    "#y_ = tf.pack([label_dict[key], label_dict[key], label_dict[key]])\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, NUM_OF_CLASS], name=\"placeholderY\")\n",
    "\n",
    "#y = tf.pack([key, key, key])\n",
    "\n",
    "# x = tf.reshape(example_batch, [-1, IMG_X * IMG_Y * 3])\n",
    "# y_ = label_batch\n",
    "\n",
    "#tf.summary.histogram(\"example_batch\",example_batch)\n",
    "#tf.summary.histogram(\"label_batch\",y_)\n",
    "\n",
    "\n",
    "# W = tf.Variable(tf.zeros([IMG_X * IMG_Y * 3, NUM_OF_CLASS]), name=\"variableWeight\")\n",
    "# w_hist = tf.summary.histogram(\"Weight_Hist\", W)\n",
    "# \n",
    "# b = tf.Variable(tf.zeros([NUM_OF_CLASS]), name=\"vaiableBias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y is x times weight + bias\n",
    "#y = tf.matmul(x,W) + b\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(20):\n",
    "#     batch = mnist.train.next_batch(10)\n",
    "#     feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "#     result = sess.run([merged, train_step], feed_dict=feed)\n",
    "#     writer.add_summary(result[0],i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_conv_prob = tf.placeholder(tf.float32, name=\"Keep_conv_prob\")\n",
    "\n",
    "#1st Layer\n",
    "with tf.name_scope('layer_1') as scope:\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    # Mode 3 for colored\n",
    "    x_image = tf.reshape(x, [-1, IMG_X, IMG_Y, 3]) \n",
    "\n",
    "    #Convolve Image by weight tensor, add bias, and apply Relu\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    #Maxpool, reduces to 14 x 14\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    h_pool1_drop = tf.nn.dropout(h_pool1, keep_conv_prob)\n",
    "\n",
    "\n",
    "#2nd Layer\n",
    "with tf.name_scope('layer_2') as scope:\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    \n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1_drop, W_conv2) + b_conv2)\n",
    "    #Maxpool, reduces to 7x7\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    h_pool2_drop = tf.nn.dropout(h_pool2, keep_conv_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Output layer\n",
    "with tf.name_scope('layer_3') as scope:\n",
    "    #Add 1024 Neuron for 7x7  image\n",
    "\n",
    "    # 7 x 7: Resolution after pooling\n",
    "    # 64: Num of features\n",
    "\n",
    "    W_fc1 = weight_variable([(IMG_X //2 // 2) * (IMG_Y //2 //2) * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    #Reshape to batch of vector\n",
    "    h_pool2_flat = tf.reshape(h_pool2_drop, [-1, (IMG_X //2 // 2) * (IMG_Y //2 //2) * 64 ])\n",
    "    \n",
    "    #Do Bias and Relu stuffs\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "    #Dropout to prevent overfit\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"Keep_prob\")\n",
    "    \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "#fl\n",
    "    #Readout\n",
    "\n",
    "    W_fc2 = weight_variable([1024, NUM_OF_CLASS])\n",
    "    b_fc2 = bias_variable([NUM_OF_CLASS])\n",
    "    \n",
    "    tf.summary.histogram(\"W_fc2\", W_fc2)\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    \n",
    "    tf.summary.histogram(\"y_conv_argmax\", tf.argmax(y_conv,1))\n",
    "    \n",
    "#Now using y_conv\n",
    "\n",
    "# Loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_), name=\"Entr\")\n",
    "cross_entropy_hist = tf.summary.scalar(\"Cross_Entropy\", cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"Acc\")\n",
    "accuracy_hist = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "#How to train\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load images\n",
    "with sess.as_default() as sess:\n",
    "    \n",
    "    with tf.name_scope(\"LoadTestImg\"):\n",
    "            def load_test_img():\n",
    "                #threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "                train_img_arr, label_img_arr = sess.run([example_batch, label_batch])\n",
    "                return [train_img_arr, label_img_arr]\n",
    "\n",
    "    if not IS_TRAINING:\n",
    "        with tf.name_scope(\"LoadValidateImg\"):\n",
    "            validate_queue = tf.train.string_input_producer([validate_filename])\n",
    "            readerVal = tf.WholeFileReader()\n",
    "            filename, dat = readerVal.read(validate_queue)\n",
    "            val_img = tf.to_float(tf.image.decode_jpeg(dat)) # use png or jpg decoder based on your files.\n",
    "\n",
    "#        patches = tf.extract_image_patches([val_img],[1, 64, 64, 1], [1, 32, 32, 1], [1, 1, 1, 1], 'SAME')\n",
    "        \n",
    "#        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "#        threads2 = tf.train.start_queue_runners(coord=coord)\n",
    "    #with sess.as_default() as sess:\n",
    "        #sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        #threads2 = tf.train.start_queue_runners(coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create saver object.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.866667 cross entropy 159.222\n",
      "step 1, training accuracy 0.883333 cross entropy 159.738\n",
      "step 2, training accuracy 0.816667 cross entropy 246.469\n",
      "step 3, training accuracy 0.933333 cross entropy 41.6365\n",
      "step 4, training accuracy 0.933333 cross entropy 43.9885\n",
      "step 5, training accuracy 0.883333 cross entropy 141.247\n",
      "step 6, training accuracy 0.95 cross entropy 29.806\n",
      "step 7, training accuracy 0.95 cross entropy 17.1162\n",
      "step 8, training accuracy 0.916667 cross entropy 91.7871\n",
      "step 9, training accuracy 0.85 cross entropy 153.256\n",
      "step 10, training accuracy 0.883333 cross entropy 100.69\n",
      "step 11, training accuracy 0.85 cross entropy 213.768\n",
      "step 12, training accuracy 0.883333 cross entropy 236.377\n",
      "step 13, training accuracy 0.916667 cross entropy 96.5996\n",
      "step 14, training accuracy 0.933333 cross entropy 90.3359\n",
      "step 15, training accuracy 0.9 cross entropy 102.891\n",
      "step 16, training accuracy 0.9 cross entropy 133.049\n",
      "step 17, training accuracy 0.933333 cross entropy 147.44\n",
      "step 18, training accuracy 0.933333 cross entropy 37.0698\n",
      "step 19, training accuracy 0.916667 cross entropy 86.6151\n",
      "step 20, training accuracy 0.933333 cross entropy 201.156\n",
      "step 21, training accuracy 1 cross entropy 0\n",
      "step 22, training accuracy 0.933333 cross entropy 91.5837\n",
      "step 23, training accuracy 0.916667 cross entropy 200.899\n",
      "step 24, training accuracy 0.916667 cross entropy 158.806\n",
      "step 25, training accuracy 0.916667 cross entropy 60.3949\n",
      "step 26, training accuracy 0.9 cross entropy 161.296\n",
      "step 27, training accuracy 0.9 cross entropy 60.1376\n",
      "step 28, training accuracy 0.9 cross entropy 157.061\n",
      "step 29, training accuracy 0.883333 cross entropy 212.478\n",
      "step 30, training accuracy 0.95 cross entropy 32.8979\n",
      "step 31, training accuracy 0.816667 cross entropy 195.785\n",
      "step 32, training accuracy 0.833333 cross entropy 313.391\n",
      "step 33, training accuracy 0.833333 cross entropy 226.966\n",
      "step 34, training accuracy 0.883333 cross entropy 154.3\n",
      "step 35, training accuracy 0.916667 cross entropy 102.968\n",
      "step 36, training accuracy 0.9 cross entropy 94.0108\n",
      "step 37, training accuracy 0.933333 cross entropy 75.6839\n",
      "step 38, training accuracy 0.933333 cross entropy 45.006\n",
      "step 39, training accuracy 1 cross entropy 0\n",
      "step 40, training accuracy 0.933333 cross entropy 16.1607\n",
      "step 41, training accuracy 0.95 cross entropy 14.7998\n",
      "step 42, training accuracy 0.95 cross entropy 26.4008\n",
      "step 43, training accuracy 0.95 cross entropy 13.5407\n",
      "step 44, training accuracy 0.883333 cross entropy 106.396\n",
      "step 45, training accuracy 0.933333 cross entropy 32.5684\n",
      "step 46, training accuracy 0.916667 cross entropy 69.596\n",
      "step 47, training accuracy 0.85 cross entropy 141.155\n",
      "step 48, training accuracy 0.933333 cross entropy 48.4583\n",
      "step 49, training accuracy 0.883333 cross entropy 97.7196\n",
      "step 50, training accuracy 0.883333 cross entropy 147.349\n",
      "step 51, training accuracy 0.9 cross entropy 103.448\n",
      "step 52, training accuracy 0.916667 cross entropy 69.5927\n",
      "step 53, training accuracy 0.916667 cross entropy 60.2167\n",
      "step 54, training accuracy 0.9 cross entropy 79.4086\n",
      "step 55, training accuracy 0.916667 cross entropy 111.712\n",
      "step 56, training accuracy 0.9 cross entropy 59.9207\n",
      "step 57, training accuracy 0.95 cross entropy 58.4573\n",
      "step 58, training accuracy 0.916667 cross entropy 73.824\n",
      "step 59, training accuracy 0.883333 cross entropy 89.2414\n",
      "step 60, training accuracy 0.933333 cross entropy 72.2448\n",
      "step 61, training accuracy 0.966667 cross entropy 66.4053\n",
      "step 62, training accuracy 0.883333 cross entropy 101.064\n",
      "step 63, training accuracy 1 cross entropy 0\n",
      "step 64, training accuracy 0.966667 cross entropy 47.0995\n",
      "step 65, training accuracy 0.966667 cross entropy 42.9165\n",
      "step 66, training accuracy 1 cross entropy 0\n",
      "step 67, training accuracy 1 cross entropy 0\n",
      "step 68, training accuracy 0.983333 cross entropy 11.1276\n",
      "step 69, training accuracy 0.983333 cross entropy 1.69598\n",
      "step 70, training accuracy 0.9 cross entropy 83.8921\n",
      "step 71, training accuracy 0.883333 cross entropy 123.437\n",
      "step 72, training accuracy 0.9 cross entropy 86.4482\n",
      "step 73, training accuracy 0.916667 cross entropy 96.5886\n",
      "step 74, training accuracy 0.916667 cross entropy 94.8681\n",
      "step 75, training accuracy 0.966667 cross entropy 23.602\n",
      "step 76, training accuracy 0.916667 cross entropy 41.2696\n",
      "step 77, training accuracy 0.9 cross entropy 110.818\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "/tmp/skin_saves/vars.ckpt.meta.tmp46db2d12b23a4e9c98b73160641078a2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d96de95cbdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;31m#Save variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/tmp/skin_saves/vars.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1373\u001b[0m           checkpoint_file, meta_graph_suffix=meta_graph_suffix)\n\u001b[1;32m   1374\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         clear_devices=clear_devices)\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m       \u001b[0mexport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1631\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[0;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         as_text=as_text)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mscoped_meta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[0;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[0;34m(filename, contents)\u001b[0m\n\u001b[1;32m    350\u001b[0m   \"\"\"\n\u001b[1;32m    351\u001b[0m   \u001b[0mtemp_pathname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".tmp\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m   \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite_string_to_file\u001b[0;34m(filename, file_content)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \"\"\"\n\u001b[1;32m    248\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       pywrap_tensorflow.AppendToFile(\n\u001b[0;32m---> 93\u001b[0;31m           compat.as_bytes(file_content), self._writable_file, status)\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: /tmp/skin_saves/vars.ckpt.meta.tmp46db2d12b23a4e9c98b73160641078a2"
     ]
    }
   ],
   "source": [
    "if IS_TRAINING:\n",
    "    #Do Training\n",
    "    with sess.as_default() as sess:\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        merged = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(\"/tmp/mnist_logs\", sess.graph)\n",
    "        # coord = tf.train.Coordinator()\n",
    "        # threads = tf.train.start_queue_runners(coord=coord)\n",
    "        #img = [sess.run(my_img) for i in range(3)]\n",
    "\n",
    "\n",
    "        #_filename,img = sess.run([key, my_img])\n",
    "        #filename = _filename.decode(\"utf-8\") #Converts from bytes type\n",
    "        #print(filename.upper()[0])\n",
    "\n",
    "        #print(label_dict[filename])\n",
    "\n",
    "\n",
    "        #expected_result = tf.reshape(label_dict[filename], [-1, 2]).eval()\n",
    "\n",
    "        #for i in range(8):\n",
    "\n",
    "        # load batch\n",
    "\n",
    "        with CoordinatorScope() as scope:\n",
    "            with ThreadScope(scope):\n",
    "                for i in range(500):\n",
    "                    if (i > 1 or True ):\n",
    "                        saver.restore(sess, '/tmp/skin_saves/vars.ckpt')\n",
    "                    train_img_arr, label_img_arr = load_test_img()\n",
    "                    result, _ = sess.run([merged, train_step], feed_dict={\n",
    "                        x: tf.reshape(train_img_arr, [-1, IMG_X * IMG_Y * 3]).eval(),\n",
    "                        y_: label_img_arr,\n",
    "                        keep_prob: 0.5,\n",
    "                        keep_conv_prob: 0.7})\n",
    "                    writer.add_summary(result,i)\n",
    "                    train_accuracy, cross = sess.run([accuracy, cross_entropy], feed_dict={\n",
    "                        x: tf.reshape(train_img_arr, [-1, IMG_X * IMG_Y * 3]).eval(),\n",
    "                        y_: label_img_arr,\n",
    "                        keep_prob: 1.0,\n",
    "                        keep_conv_prob: 1.0})\n",
    "                    print(\"step %d, training accuracy %g cross entropy %g\"%(i, train_accuracy, cross))\n",
    "                    \n",
    "                    #Save variable\n",
    "                    saver.save(sess, '/tmp/skin_saves/vars.ckpt')\n",
    "\n",
    "\n",
    "        #coord.request_stop()\n",
    "        #coord.join(threads)\n",
    "        #for i in range(1):\n",
    "        #        batch = mnist.train.next_batch(500)\n",
    "        #        if i%100 == 0:\n",
    "        #            train_accuracy = sess.run(accuracy, feed_dict={\n",
    "        #                x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        #            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        #            result, _ = sess.run([merged, train_step], feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.8})\n",
    "        #            writer.add_summary(result,i)\n",
    "\n",
    "else:\n",
    "    print(\"TRAINING SKIPPED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not(IS_TRAINING):\n",
    "    #Load variable\n",
    "    with sess.as_default() as sess:\n",
    "        saver.restore(sess, '/tmp/skin_saves/vars.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"DONE\")\n",
    "if (IS_TRAINING):\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = {}\n",
    "classes = ['healthy', 'junk']\n",
    "#with sess.as_default() as sess:\n",
    "    #print(sess.run(tf.argmax(y_conv,1), feed_dict={keep_prob: 1.0}))\n",
    "#    for clsName in classes:\n",
    "#        classIdx = sess.run([tf.argmax([label],1)], feed_dict={filename_before_space: clsName})[0][0]\n",
    "#        c[classIdx] = clsName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with sess.as_default() as sess:\n",
    "#    fname, patches_arr = sess.run([filename,patches])\n",
    "\n",
    "with CoordinatorScope() as coord:\n",
    "    with ThreadScope(coord):\n",
    "        validate_accuracy = sess.run(y_conv, feed_dict={\n",
    "            x: tf.reshape(val_img, [-1, IMG_X * IMG_Y * 3]).eval(),\n",
    "            #y_: label_img_arr,\n",
    "            keep_prob: 1.0,\n",
    "            keep_conv_prob: 1.0})\n",
    "\n",
    "print(validate_accuracy)\n",
    "result_dict = {}\n",
    "\n",
    "#for classIdx in validate_accuracy:\n",
    "#    if classIdx in c:\n",
    "#        key_grouped = c[classIdx]\n",
    "#        key_grouped = key_grouped[0:key_grouped.find('_')]\n",
    "#        if key_grouped in result_dict:\n",
    "#            result_dict[key_grouped]+=1\n",
    "#        else:\n",
    "#            result_dict[key_grouped]=1#\n",
    "#\n",
    "#print(\"Filename:\",fname.decode('UTF-8'), sorted(result_dict.items(), key=operator.itemgetter(1), reverse=True))\n",
    "#Opens file for writing\n",
    "\n",
    "with open(validate_filename + \".txt\", 'w') as f:\n",
    "    print(classes[np.argmax(validate_accuracy)], file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validate_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Plotting Stuffs\n",
    "\n",
    "# with sess.as_default() as sess:\n",
    "#     f = sess.run(tf.unstack(h_conv1, axis=-1), feed_dict = {\n",
    "#         x: tf.reshape(patches_arr, [-1, IMG_X * IMG_Y * 3]).eval(),\n",
    "#         keep_prob: 1.0})\n",
    "#     \n",
    "#     #print(f)\n",
    "#     for i in range(30):\n",
    "#         plt.figure(i, figsize=(2,2))\n",
    "#         plt.imshow(f[30][i], interpolation='none', vmax=9)\n",
    "#         plt.colorbar()\n",
    "        \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
